AI log QnA + analyser using locally deployed llm.

Step 1) install ollama cli
Step 2) pull qwen3 thinking model and build it using modelFile defined in code.
Step 3) Get a test file (something like test.csv) and start chat by doing chat.py.


For personal/new logs, you might need to update entity_mappings.yaml
